{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e08f31e-703d-4870-b7bc-f59fe8d8dfc9",
   "metadata": {},
   "source": [
    "# This script is estimating the domain size of active material from cross-sectional SEM\n",
    "\n",
    "## How should the format be for the files?\n",
    "\n",
    "Just the .tif files from the JEOL SEM will work fine.\n",
    "\n",
    "## How do I use this script? I don't know any coding...\n",
    "\n",
    "No problem, this one is a bit more advanced than the other scripts but not much more\n",
    "\n",
    "### Step 1\n",
    "\n",
    "You should see a blue bar to the left of this text, this refers to which part of the code the system will read next. To have the system read the code, just hit Shift+Enter and it will go to the next \"Cell\"\n",
    "\n",
    "### Step 2\n",
    "\n",
    "Each cell will have a Blurb at the top with a # before it, this is meant to tell you what the cell is doing. There are some cells that you don't need to worry about changing and others that only need very minor input.\n",
    "\n",
    "Read the blurb, if it says \"#Don't worry about it\", then just hit Shift+Enter\n",
    "\n",
    "You can tell if the cell is done running by either an output such as a number or plot OR it will read \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aec732-867d-4e94-b352-8b25568643d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Wess van den Bergh\n",
    "#Date Modified: May 16, 2024\n",
    "#Environment: v2_Pharmakinetics\n",
    "#Verified By: \n",
    "\n",
    "#Notes, known errors, desired features\n",
    "\n",
    "# May still spit out WARNINGS\n",
    "# Not tested with other images so robustness with range of image qualities is unknown\n",
    "# Not directly compared with other methods -- some imageJ comparisons that are roughly inline\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef7c53-bede-4d8e-9e7c-7c69efec5d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Don't worry about it, just hit Shift+Enter\n",
    "\n",
    "#importing necessary functions\n",
    "import skimage as ski\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tkinter import*\n",
    "import pyclesperanto_prototype as cle\n",
    "import pandas as pd\n",
    "import stackview\n",
    "import os\n",
    "import warnings\n",
    "import cmcrameri as cmc\n",
    "\n",
    "#Specific functions\n",
    "from napari_segment_blobs_and_things_with_membranes import voronoi_otsu_labeling\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from napari_skimage_regionprops import regionprops_table\n",
    "from napari_simpleitk_image_processing import label_statistics\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def import_then_process_img():\n",
    "    \"\"\" grabs the image with a GUI for domain size analysis \"\"\"\n",
    "    # Create Tk root\n",
    "    root = Tk()\n",
    "    # Hide the main window\n",
    "    root.withdraw()\n",
    "    root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "    \n",
    "    from tkinter import filedialog\n",
    "    img_filepath = filedialog.askopenfilename(multiple=False)\n",
    "    \n",
    "    %gui tk\n",
    "    \n",
    "    if '.tif' not in repr(img_filepath) and '.tiff' not in repr(img_filepath):\n",
    "        wanrings.warn(\"image is not a .tiff or .tif file\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #run a test to see if the file is RGBA or RGB AND turn the image to grayscale\n",
    "    try:\n",
    "        temp_grayscale_image = ski.color.rgb2gray(ski.color.rgba2rgb(ski.io.imread(img_filepath)))\n",
    "        try:\n",
    "            temp_grayscale_image = ski.color.rgb2gray(ski.io.imread(img_filepath))\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        warnings.warn(\"not RGB or RGBA image\")\n",
    "    \n",
    "    plt.imshow(temp_grayscale_image)\n",
    "    plt.show()\n",
    "    \n",
    "    scalebar_point = int(input(\"What is an intersecting X-value with the scalebar? \"))\n",
    "    scalebar_size = int(input(\"What is the size of the scalebar? \"))\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    img_list = img_remove_watermark_set_scale(temp_grayscale_image, scalebar_point, scalebar_size) #returns the image and the microns per pixel scale of the image as a float/scalar\n",
    "\n",
    "    crop_yn = input(\"Does the image need to be cropped? (y/n) \")\n",
    "\n",
    "    if crop_yn.lower() in ['true', '1', 't', 'y', 'yes']:\n",
    "        crop_lower_input_value = int(input(\"What is the lower-end crop Y (bottom portion) value? \"))\n",
    "        crop_upper_input_value = int(input(\"What is the upper-end crop Y (top portion) value? \"))\n",
    "        temp_image_grayscale = img_crop(img_list[0], crop_upper = crop_upper_input_value, crop_lower = crop_lower_input_value)\n",
    "\n",
    "    else:\n",
    "        temp_image_grayscale = img_list[0]\n",
    "    \n",
    "    return temp_image_grayscale, img_list[1]\n",
    "\n",
    "def img_remove_watermark_set_scale(temp_grayscale_image, scalebar_point, scalebar_size):\n",
    "    \"\"\" removes the watermark from the SEM image and converts it to grayscale \"\"\"\n",
    "\n",
    "    #finding scale scalebar size in pixels\n",
    "    j = temp_grayscale_image.shape[0] - 1\n",
    "    while temp_grayscale_image[j, scalebar_point] != 1.0:\n",
    "        j -= 1\n",
    "    j -= 3 #not sure why I wrote this, either as precaution or to account for something with the scalebar\n",
    "    \n",
    "    while temp_grayscale_image[j, scalebar_point] == 1.0:\n",
    "        scalebar_point -= 1\n",
    "    scalebar_point_start = scalebar_point\n",
    "    \n",
    "    scalebar_point += 1\n",
    "    while temp_grayscale_image[j, scalebar_point] == 1.0:\n",
    "        scalebar_point += 1\n",
    "    scalebar_point_end = scalebar_point\n",
    "    \n",
    "    scalebar_pixel_length = scalebar_point_end - scalebar_point_start\n",
    "    micron_per_pixel = scalebar_size / scalebar_pixel_length\n",
    "\n",
    "    #crop image to remove watermarks\n",
    "    i = temp_grayscale_image.shape[0] - 1\n",
    "    while temp_grayscale_image[i, 3] == 0.0:\n",
    "        i -= 1\n",
    "    temp_grayscale_image = temp_grayscale_image[0:i, :]\n",
    "    \n",
    "    plt.minorticks_on()\n",
    "    plt.tick_params(axis='both', which='minor', length=4, width=1, direction='out')\n",
    "    \n",
    "    plt.imshow(temp_grayscale_image)\n",
    "    plt.show()\n",
    "\n",
    "    return [temp_grayscale_image, micron_per_pixel]\n",
    "\n",
    "def img_crop(temp_grayscale_image, crop_upper = 0, crop_lower = 0):\n",
    "    \"\"\" has the user input the y-values to crop the image to remove anything that is not of interest \"\"\"\n",
    "    \n",
    "    if crop_upper != 0:\n",
    "        temp_grayscale_image = temp_grayscale_image[crop_upper:-1, :]\n",
    "        \n",
    "    if crop_lower != 0 and crop_upper != 0:\n",
    "        temp_grayscale_image = temp_grayscale_image[0:(crop_lower-crop_upper), :]\n",
    "    elif crop_lower != 0 and crop_upper == 0:\n",
    "        temp_grayscale_image = temp_grayscale_image[0:(crop_lower), :]\n",
    "\n",
    "    plt.minorticks_on()\n",
    "    plt.tick_params(axis='both', which='minor', length=4, width=1, direction='out')\n",
    "    plt.imshow(temp_grayscale_image)\n",
    "    plt.show()\n",
    "    return temp_grayscale_image\n",
    "\n",
    "\n",
    "\n",
    "def try_all_thresholds(temp_grayscale_image):\n",
    "    \"\"\" spits out an array of threshold methods that the user might find interesting \"\"\"\n",
    "    fig, ax = ski.filters.try_all_threshold(temp_grayscale_image, figsize = (20, 16), verbose = False)\n",
    "    plt.show()\n",
    "\n",
    "    threshold_selection = input(\"By name or threshold number, what is the best option for you? \")\n",
    "\n",
    "    try:\n",
    "        float(threshold_selection)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    temp_image_binary = img_threshold(temp_grayscale_image, threshold_selection)\n",
    "    \n",
    "    return temp_image_binary\n",
    "\n",
    "def img_threshold(temp_grayscale_image, selctn):\n",
    "    \"\"\" applies the threshold of choice or takes a float value for thresholding if none are satisfactory \"\"\"\n",
    "    if selctn.lower() == \"isodata\":\n",
    "        thresh = ski.filters.threshold_isodata(temp_grayscale_image)\n",
    "    elif selctn.lower() == \"li\":\n",
    "        thresh = ski.filters.threshold_li(temp_grayscale_image)\n",
    "    elif selctn.lower() == \"mean\":\n",
    "        thresh = ski.filters.threshold_mean(temp_grayscale_image)\n",
    "    elif selctn.lower() == \"minimum\":\n",
    "        thresh = ski.filters.threshold_minimum(temp_grayscale_image)\n",
    "    elif selctn.lower() == \"otsu\":\n",
    "        thresh = ski.filters.threshold_otsu(temp_grayscale_image)\n",
    "    elif selctn.lower() == \"triangle\":\n",
    "        thresh = ski.filters.threshold_triangle(temp_grayscale_image)\n",
    "    elif selctn.lower() == \"yen\":\n",
    "        thresh = ski.filters.threshold_yen(temp_grayscale_image)\n",
    "    elif isinstance(selctn, float):\n",
    "        thresh = selctn\n",
    "\n",
    "    temp_image_binary = temp_grayscale_image > thresh\n",
    "    \n",
    "    return temp_image_binary\n",
    "\n",
    "\n",
    "def img_erosion_n_fill(temp_image_binary, erosion_range = 4):\n",
    "    \"\"\" \n",
    "    shows an array of erosion value options to see which erosion value is best to remove excess\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axs = plt.subplots(erosion_range, 1, figsize=(15,20))\n",
    "    cle.imshow(temp_image_binary, plot=axs[0])\n",
    "    axs[0].set_title('Binary image')\n",
    "    for i in range(1, erosion_range):\n",
    "        temp_eroded_binary = ski.morphology.binary_erosion(temp_image_binary, ski.morphology.disk(i))\n",
    "        stackview.imshow(temp_eroded_binary, plot=axs[i])\n",
    "        axs[i].set_title('Eroded r={}'.format(i))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    erosion_value = int(input(\"What erosion value do you want to apply? (0 for no erosion): \"))\n",
    "    eroded_binary = img_erosion_apply(temp_image_binary, erosion_value)\n",
    "    eroded_fill_treated_binary = img_hole_fill(eroded_binary)\n",
    "    second_erosion_decision = input(\"After hole filling, does the image need a second round of erosion? (y/n): \")\n",
    "    \n",
    "    plt.clf\n",
    "\n",
    "    if second_erosion_decision.lower() in ['true', '1', 't', 'y', 'yes']:\n",
    "        \n",
    "        fig, axs = plt.subplots(erosion_range, 1, figsize=(15,20))\n",
    "        cle.imshow(eroded_fill_treated_binary, plot=axs[0])\n",
    "        axs[0].set_title('Binary image')\n",
    "        for i in range(1, erosion_range):\n",
    "            temp_eroded_binary = ski.morphology.binary_erosion(eroded_fill_treated_binary, ski.morphology.disk(i))\n",
    "            stackview.imshow(eroded_fill_treated_binary, plot=axs[i])\n",
    "            axs[i].set_title('Eroded r={}'.format(i))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        second_erosion_value = int(input(\"What erosion value do you want to apply? (0 for no erosion): \"))\n",
    "        second_eroded_fill_treated_binary = img_erosion_apply(eroded_fill_treated_binary, second_erosion_value)\n",
    "        return second_eroded_fill_treated_binary\n",
    "    else:\n",
    "        return eroded_fill_treated_binary\n",
    "\n",
    "def img_erosion_apply(temp_image_binary, erosion_value):\n",
    "    \"\"\" \n",
    "    used to wash out extra stuff/noise picked up that is not particles\n",
    "    note that it also erodes edges of particles so use sparingly\n",
    "    \"\"\"\n",
    "    eroded_binary = ski.morphology.binary_erosion(temp_image_binary, ski.morphology.disk(erosion_value))\n",
    "    return eroded_binary\n",
    "\n",
    "\n",
    "\n",
    "def img_hole_fill(temp_image_binary):\n",
    "    \"\"\" \n",
    "    fills the holes in particles, this may not be necessary or undesired so consider it optional\n",
    "    \"\"\"\n",
    "    \n",
    "    fill_decision = input(\"Do you want to fill in the holes of the particles?: (y/n)\")\n",
    "    \n",
    "    if fill_decision.lower() in ['true', '1', 't', 'y', 'yes']:\n",
    "    \n",
    "        filled_binary = binary_fill_holes(temp_image_binary)\n",
    "\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "        cle.imshow(temp_image_binary, plot=axs[0])\n",
    "        axs[0].set_title('Binary image')\n",
    "\n",
    "        cle.imshow(filled_binary, plot=axs[1])\n",
    "        axs[1].set_title('Holes filled')\n",
    "\n",
    "        return filled_binary\n",
    "    \n",
    "    else:\n",
    "        return temp_image_binary\n",
    "\n",
    "\n",
    "def img_binary_labeling(temp_image_binary, \n",
    "                        spot_sigma_val = 15,\n",
    "                        outline_sigma_val = 0):\n",
    "    \"\"\" \n",
    "    IDs individual particles with two different methods as neither method is perfect, thus two imperfect ones are used\n",
    "    \"\"\"\n",
    "    voroni_otsu_lbls = voronoi_otsu_labeling(temp_image_binary, \n",
    "                                             spot_sigma = spot_sigma_val, \n",
    "                                             outline_sigma = outline_sigma_val)\n",
    "    cle.imshow(voroni_otsu_lbls, labels = True)\n",
    "    von_neumann_lbls = ski.measure.label(temp_image_binary, connectivity = 1)\n",
    "    cle.imshow(von_neumann_lbls, labels=True)\n",
    "\n",
    "    return [von_neumann_lbls, voroni_otsu_lbls]\n",
    "\n",
    "\n",
    "def img_binary_enframing(temp_grayscale_image, von_neumann_lbls, voroni_otsu_lbls, micron_per_pixel):\n",
    "    \"\"\" \n",
    "    Applies data values to the particles idenified -- uses two enframing methods to grab the necessary values\n",
    "    \"\"\"\n",
    "    voroni_otsu_df_perim = pd.DataFrame(label_statistics(temp_grayscale_image, voroni_otsu_lbls,  \n",
    "                                  shape=False, \n",
    "                                  perimeter=True, \n",
    "                                  position=False,\n",
    "                                  moments=False))\n",
    "    \n",
    "    von_neumann_df_perim = pd.DataFrame(label_statistics(temp_grayscale_image, von_neumann_lbls,  \n",
    "                                  shape=False, \n",
    "                                  perimeter=True, \n",
    "                                  position=False,\n",
    "                                  moments=False))\n",
    "    \n",
    "    voroni_otsu_df = pd.DataFrame(regionprops_table(temp_grayscale_image , voroni_otsu_lbls, \n",
    "                                               perimeter = True, \n",
    "                                               shape = True, \n",
    "                                               position=True,\n",
    "                                               moments=False))\n",
    "    \n",
    "    von_neumann_df = pd.DataFrame(regionprops_table(temp_grayscale_image , von_neumann_lbls, \n",
    "                                               perimeter = True, \n",
    "                                               shape = True, \n",
    "                                               position=True,\n",
    "                                               moments=False))\n",
    "    \n",
    "    voroni_otsu_df = pd.concat([voroni_otsu_df, voroni_otsu_df_perim['perimeter_on_border_ratio']], axis = 1)\n",
    "    von_neumann_df = pd.concat([von_neumann_df, von_neumann_df_perim['perimeter_on_border_ratio']], axis = 1)\n",
    "    \n",
    "    voroni_otsu_df['equivalent_diameter'] = voroni_otsu_df['equivalent_diameter'] * micron_per_pixel\n",
    "    von_neumann_df['equivalent_diameter'] = von_neumann_df['equivalent_diameter'] * micron_per_pixel\n",
    "    voroni_otsu_df['area'] = voroni_otsu_df['area'] * (micron_per_pixel ** 2)\n",
    "    von_neumann_df['area'] = von_neumann_df['area'] * (micron_per_pixel ** 2)\n",
    "\n",
    "    return [von_neumann_df, voroni_otsu_df]\n",
    "\n",
    "\n",
    "\n",
    "def cutoff_particle_size(von_neumann_df, voroni_otsu_df):\n",
    "    \"\"\" \n",
    "    Noise will be ID'd as particles as well, this is meant to set a cutoff to remove that noise to get a more accurate analysis\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.ecdf(voroni_otsu_df['equivalent_diameter'], label = 'Voroni Otsu')\n",
    "    plt.ecdf(von_neumann_df['equivalent_diameter'], label = 'Von Neumann')\n",
    "    \n",
    "    ax.set_xlim([0, 5])\n",
    "    \n",
    "    plt.xlabel('Equiv. Diameter (microns)')\n",
    "    plt.ylabel('ECDF')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Average value of Von Neumann labeling: {}\".format(von_neumann_df['equivalent_diameter'].mean()))\n",
    "    print(\"Average value of Voroni Otsu labeling: {}\".format(voroni_otsu_df['equivalent_diameter'].mean()))\n",
    "    \n",
    "\n",
    "def cutoff_particles_on_edge(von_neumann_filtered_df, voroni_otsu_filtered_df):\n",
    "    \"\"\" \n",
    "    Particles at the edge will be ID'd as particles as well, this is meant to set a cutoff to remove that noise to get a more accurate analysis\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    plt.ecdf(voroni_otsu_filtered_df['perimeter_on_border_ratio'], label = 'Voroni Otsu')\n",
    "    plt.ecdf(von_neumann_filtered_df['perimeter_on_border_ratio'], label = 'Von Neumann')\n",
    "    \n",
    "    plt.xlabel('Ratio of Perimeter on Border')\n",
    "    plt.ylabel('ECDF')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Average value of Voroni Otsu labeling: {}\".format(voroni_otsu_filtered_df['perimeter_on_border_ratio'].mean()))\n",
    "    print(\"Average value of Von Neumann labeling: {}\".format(von_neumann_filtered_df['perimeter_on_border_ratio'].mean()))\n",
    "\n",
    "\n",
    "def cutoff_particle_apply(von_neumann_df, voroni_otsu_df, cutoff_type, cutoff_value):\n",
    "    \"\"\" \n",
    "    Application of cutoff value for particle size\n",
    "    \"\"\"\n",
    "    if cutoff_type == \"size\":\n",
    "        von_neumann_df = von_neumann_df[von_neumann_df['equivalent_diameter'] > cutoff_value]\n",
    "        voroni_otsu_df = voroni_otsu_df[voroni_otsu_df['equivalent_diameter'] > cutoff_value]\n",
    "        \n",
    "    elif cutoff_type == \"edge\":\n",
    "        von_neumann_df = von_neumann_df[von_neumann_df['perimeter_on_border_ratio'] < cutoff_value]\n",
    "        voroni_otsu_df = voroni_otsu_df[voroni_otsu_df['perimeter_on_border_ratio'] < cutoff_value]\n",
    "\n",
    "    return [von_neumann_df, voroni_otsu_df]   \n",
    "\n",
    "def finalize_data(von_neumann_filtered2_df, voroni_otsu_filtered2_df):\n",
    "    \"\"\" \n",
    "    seeks to determine if there are any remaining outliers albiet the cutoff for which is pretty generous\n",
    "    \"\"\"\n",
    "\n",
    "    # After removing speck outliers then apply MAD outlier filter with cutoff value = 3 (http://dx.doi.org/10.1016/j.jesp.2013.03.013)\n",
    "    von_neumann_filtered2_df['preMAD_diam'] = abs(von_neumann_filtered2_df['equivalent_diameter'] - von_neumann_filtered2_df['equivalent_diameter'].median()) \n",
    "    voroni_otsu_filtered2_df['preMAD_diam'] = abs(voroni_otsu_filtered2_df['equivalent_diameter'] - voroni_otsu_filtered2_df['equivalent_diameter'].median())\n",
    "    \n",
    "    von_neumann_filtered2_df['MAD_diam'] = (von_neumann_filtered2_df['equivalent_diameter'] - von_neumann_filtered2_df['equivalent_diameter'].median()) / (1.4826 * von_neumann_filtered2_df['preMAD_diam'].median())\n",
    "    voroni_otsu_filtered2_df['MAD_diam'] = (voroni_otsu_filtered2_df['equivalent_diameter'] - voroni_otsu_filtered2_df['equivalent_diameter'].median()) / (1.4826 * voroni_otsu_filtered2_df['preMAD_diam'].median())\n",
    "    \n",
    "    von_neumann_filtered3_df = von_neumann_filtered2_df[abs(von_neumann_filtered2_df['perimeter_on_border_ratio']) < 3]\n",
    "    voroni_otsu_filtered3_df = voroni_otsu_filtered2_df[abs(voroni_otsu_filtered2_df['perimeter_on_border_ratio']) < 3]\n",
    "    \n",
    "    print(\"Number of outliers removed from Von Neumman method: {}\".format(len(von_neumann_filtered2_df.index) % len(von_neumann_filtered3_df.index)))\n",
    "    print(\"Number of outliers removed from Voroni Otsu method: {}\".format(len(voroni_otsu_filtered2_df.index) % len(voroni_otsu_filtered3_df.index)))\n",
    "\n",
    "    return [von_neumann_filtered3_df, voroni_otsu_filtered3_df]\n",
    "\n",
    "\n",
    "\n",
    "def plot_and_process_particle_data(temp_grayscale_image, \n",
    "                                   von_neumann_filtered3_df, \n",
    "                                   von_neumann_lbls, \n",
    "                                   voroni_otsu_filtered3_df, \n",
    "                                   voroni_otsu_lbls,\n",
    "                                   experiment_id_for_file = None,\n",
    "                                   consolidated_data = False\n",
    "                                  ):\n",
    "\n",
    "    if consolidated_data == False:\n",
    "        plot_data(temp_grayscale_image, \n",
    "                  von_neumann_filtered3_df, \n",
    "                  von_neumann_lbls, \n",
    "                  voroni_otsu_filtered3_df, \n",
    "                  voroni_otsu_lbls,\n",
    "                  consolidated_plot_data = False\n",
    "                 )\n",
    "    \n",
    "        if isinstance(experiment_id_for_file, str) == True:\n",
    "            save_domain_size_df(von_neumann_filtered3_df,\n",
    "                                df_type = \"von_neumann\",\n",
    "                                experiment_id = experiment_id_for_file)\n",
    "        \n",
    "            save_domain_size_df(voroni_otsu_filtered3_df,\n",
    "                                df_type = \"voroni_otsu\",\n",
    "                                experiment_id = experiment_id_for_file)\n",
    "\n",
    "    if consolidated_data == True:\n",
    "        plot_data(temp_grayscale_image = None, \n",
    "                  von_neumann_filtered3_df = von_neumann_filtered3_df, \n",
    "                  von_neumann_lbls = None, \n",
    "                  voroni_otsu_filtered3_df = voroni_otsu_filtered3_df, \n",
    "                  voroni_otsu_lbls = None,\n",
    "                  consolidated_plot_data = True\n",
    "                 )\n",
    "\n",
    "def plot_data(temp_grayscale_image, \n",
    "              von_neumann_filtered3_df, \n",
    "              von_neumann_lbls, \n",
    "              voroni_otsu_filtered3_df, \n",
    "              voroni_otsu_lbls,\n",
    "              ax_font_size = 14,\n",
    "              consolidated_plot_data = False\n",
    "             ):\n",
    "    \"\"\" \n",
    "    Plots the data and reports the statistics \n",
    "    \"\"\"\n",
    "\n",
    "    BINS_FOR_HISTOGRAM = np.linspace(0.0, 10, 41, endpoint=True)\n",
    "\n",
    "    if temp_grayscale_image.all(None) == False: #If there is an image rather than a None input\n",
    "        # Hit shift+enter, here are the domains contained by \"bounding boxes\" as well as the stats and violin plots\n",
    "        # Bounding Box plot for von neumann\n",
    "        plt.imshow(temp_grayscale_image, cmap = 'gray')\n",
    "        for index, row in von_neumann_filtered3_df.iterrows():\n",
    "            bbox_min = (row['bbox-1'], row['bbox-0'])\n",
    "            bbox_max = (row['bbox-3'], row['bbox-2'])\n",
    "            width = bbox_max[0] - bbox_min[0]\n",
    "            height = bbox_max[1] - bbox_min[1]\n",
    "            rect = plt.Rectangle(bbox_min, width, height, edgecolor='r', facecolor='none')\n",
    "            plt.gca().add_patch(rect)\n",
    "        plt.title('Von Neumann Domains')\n",
    "        plt.show()\n",
    "        \n",
    "        # Bounding Box plot for von neumann\n",
    "        plt.imshow(cle.pull(von_neumann_lbls), cmap='nipy_spectral')  # Convert labeled_image to numpy array before plotting\n",
    "        for index, row in von_neumann_filtered3_df.iterrows():\n",
    "            bbox_min = (row['bbox-1'], row['bbox-0'])\n",
    "            bbox_max = (row['bbox-3'], row['bbox-2'])\n",
    "            width = bbox_max[0] - bbox_min[0]\n",
    "            height = bbox_max[1] - bbox_min[1]\n",
    "            rect = plt.Rectangle(bbox_min, width, height, edgecolor='w', facecolor='none')\n",
    "            plt.gca().add_patch(rect)\n",
    "        plt.title('Von Neumann Domains_2')\n",
    "        plt.show()\n",
    "        \n",
    "        # Bounding Box plot for von neumann\n",
    "        plt.imshow(temp_grayscale_image, cmap = 'gray')\n",
    "        for index, row in voroni_otsu_filtered3_df.iterrows():\n",
    "            bbox_min = (row['bbox-1'], row['bbox-0'])\n",
    "            bbox_max = (row['bbox-3'], row['bbox-2'])\n",
    "            width = bbox_max[0] - bbox_min[0]\n",
    "            height = bbox_max[1] - bbox_min[1]\n",
    "            rect = plt.Rectangle(bbox_min, width, height, edgecolor='b', facecolor='none')\n",
    "            plt.gca().add_patch(rect)   \n",
    "        plt.title('Voroni Otsu Domains')\n",
    "        plt.show()\n",
    "        \n",
    "        # Bounding Box plot for von neumann\n",
    "        plt.imshow(cle.pull(voroni_otsu_lbls), cmap='nipy_spectral')  # Convert labeled_image to numpy array before plotting\n",
    "        for index, row in voroni_otsu_filtered3_df.iterrows():\n",
    "            bbox_min = (row['bbox-1'], row['bbox-0'])\n",
    "            bbox_max = (row['bbox-3'], row['bbox-2'])\n",
    "            width = bbox_max[0] - bbox_min[0]\n",
    "            height = bbox_max[1] - bbox_min[1]\n",
    "            rect = plt.Rectangle(bbox_min, width, height, edgecolor='w', facecolor='none')\n",
    "            plt.gca().add_patch(rect)\n",
    "        plt.title('Voroni Otsu Domains_2')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    if consolidated_plot_data == True:\n",
    "        # Create Tk root\n",
    "        root = Tk()\n",
    "        # Hide the main window\n",
    "        root.withdraw()\n",
    "        root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "        \n",
    "        from tkinter import filedialog\n",
    "        df_csvs = filedialog.askopenfilename(multiple=True)\n",
    "        \n",
    "        %gui tk\n",
    "        \n",
    "        von_neumann_dfs = []\n",
    "        voroni_otsu_dfs = []\n",
    "        \n",
    "        for i, path in enumerate(df_csvs): \n",
    "            if \"von_neumann\" in os.path.basename(path):\n",
    "                von_neumann_dfs.append(pd.read_csv(path))\n",
    "            elif \"voroni_otsu\" in os.path.basename(path):\n",
    "                voroni_otsu_dfs.append(pd.read_csv(path))\n",
    "        \n",
    "        von_neumann_filtered3_df = pd.concat(von_neumann_dfs, ignore_index = True, sort = False)\n",
    "        voroni_otsu_filtered3_df = pd.concat(voroni_otsu_dfs, ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    # Number-based stats on each measurement method\n",
    "    print(\"Von Neumann: Equivalenet Diameter Stats, number-based\")\n",
    "    von_neumann_stats = von_neumann_filtered3_df['equivalent_diameter'].describe(percentiles = [0.10, 0.50, 0.90])\n",
    "    von_neumann_stats = pd.concat([von_neumann_stats, \n",
    "                                   pd.Series([(von_neumann_stats[\"90%\"] - von_neumann_stats[\"10%\"]) / von_neumann_stats[\"10%\"]], \n",
    "                                             index = ['span'])\n",
    "                                  ]\n",
    "                                 )\n",
    "    print(von_neumann_stats)\n",
    "    print(\" \")\n",
    "\n",
    "    \n",
    "    print(\"Voroni Otsu: Equivalenet Diameter Stats, number-based\")\n",
    "    voroni_otsu_stats = voroni_otsu_filtered3_df['equivalent_diameter'].describe(percentiles = [0.10, 0.50, 0.90])\n",
    "    voroni_otsu_stats = pd.concat([voroni_otsu_stats, \n",
    "                                   pd.Series([(voroni_otsu_stats[\"90%\"] - voroni_otsu_stats[\"10%\"]) / voroni_otsu_stats[\"10%\"]], \n",
    "                                             index = ['span'])\n",
    "                                  ]\n",
    "                                 )\n",
    "    print(voroni_otsu_stats)\n",
    "    print(\" \")\n",
    "    \n",
    "    #Histogram PSD plots for NUMBER VALUES\n",
    "    fig_num_psd, ax_num_psd = plt.subplots()\n",
    "    voroni_otsu_filtered3_df['equivalent_diameter'].plot(kind = 'density', \n",
    "                                                         color = cmc.cm.vikO(0.15),\n",
    "                                                         lw = 3\n",
    "                                                        )\n",
    "    von_neumann_filtered3_df['equivalent_diameter'].plot(kind = 'density', \n",
    "                                                         color = cmc.cm.vikO(0.80),\n",
    "                                                         lw = 3\n",
    "                                                        )\n",
    "    \n",
    "    plt.hist(voroni_otsu_filtered3_df['equivalent_diameter'], \n",
    "             bins = BINS_FOR_HISTOGRAM, \n",
    "             density = True, \n",
    "             alpha = 0.3, \n",
    "             color = cmc.cm.vikO(0.15)\n",
    "            )\n",
    "    plt.hist(von_neumann_filtered3_df['equivalent_diameter'], \n",
    "             bins = BINS_FOR_HISTOGRAM, \n",
    "             density = True, \n",
    "             alpha = 0.3,\n",
    "             color = cmc.cm.vikO(0.80)\n",
    "            )\n",
    "    \n",
    "    plt.xlabel('#-wt\\'d Equivalent Diameter (microns)', fontsize = ax_font_size, fontweight = 'bold')\n",
    "    plt.ylabel('Density',  fontsize = ax_font_size, fontweight = 'bold')\n",
    "    plt.xticks(fontsize=ax_font_size, fontweight='bold')\n",
    "    plt.yticks(fontsize=ax_font_size, fontweight='bold')\n",
    "    plt.box(True)\n",
    "    plt.gca().spines['top'].set_linewidth(4)    # Set top spine thickness\n",
    "    plt.gca().spines['bottom'].set_linewidth(4) # Set bottom spine thickness\n",
    "    plt.gca().spines['left'].set_linewidth(4)   # Set left spine thickness\n",
    "    plt.gca().spines['right'].set_linewidth(4)  # Set right spine thickness\n",
    "    plt.tick_params(axis='both', direction='in', length=10)  # Set the length of tick marks\n",
    "    \n",
    "    ax_num_psd.set_ylim([0, 1])\n",
    "    ax_num_psd.set_xlim([0, 10])\n",
    "    \n",
    "    num_legend = plt.legend(labels = ['voroni_otsu', 'von neumann'], framealpha=1, frameon=True, fontsize=ax_font_size - 4)\n",
    "    frame = num_legend.get_frame()\n",
    "    frame.set_edgecolor('black')  # Set legend box color\n",
    "    frame.set_linewidth(2)        # Set legend box thickness\n",
    "    for text in num_legend.get_texts():\n",
    "        text.set_fontweight('bold')\n",
    "    plt.show\n",
    "    \n",
    "    #Histogram + PSD plots for volume-based analysis\n",
    "    fig_vol_psd, ax_vol_psd = plt.subplots()\n",
    "\n",
    "    kde_voroni_otsu = gaussian_kde(voroni_otsu_filtered3_df['equivalent_diameter'], \n",
    "                                   bw_method='scott', \n",
    "                                   weights = ((4/3) * np.pi) * voroni_otsu_filtered3_df['equivalent_diameter']**3)  # Use Scott's bandwidth method for automatic adjustment\n",
    "    \n",
    "    x_values_voroni_otsu = np.linspace(min(voroni_otsu_filtered3_df['equivalent_diameter']), max(voroni_otsu_filtered3_df['equivalent_diameter']), 100)\n",
    "    y_values_voroni_otsu = kde_voroni_otsu(x_values_voroni_otsu)\n",
    "    y_values_voroni_otsu /= np.trapezoid(y_values_voroni_otsu, x_values_voroni_otsu)  # Normalizing the area under the curve to 1\n",
    "    \n",
    "    \n",
    "    kde_von_neumann = gaussian_kde(von_neumann_filtered3_df['equivalent_diameter'], \n",
    "                                   bw_method='scott', \n",
    "                                   weights = ((4/3) * np.pi) * von_neumann_filtered3_df['equivalent_diameter']**3)  # Use Scott's bandwidth method for automatic adjustment\n",
    "    \n",
    "    x_values_von_neumann = np.linspace(min(von_neumann_filtered3_df['equivalent_diameter']), max(von_neumann_filtered3_df['equivalent_diameter']), 100)\n",
    "    y_values_von_neumann = kde_von_neumann(x_values_von_neumann)\n",
    "    y_values_von_neumann /= np.trapezoid(y_values_von_neumann, x_values_von_neumann)  # Normalizing the area under the curve to 1\n",
    "    \n",
    "    # Step 4: Plot the KDE\n",
    "    plt.plot(x_values_voroni_otsu, \n",
    "             y_values_voroni_otsu, \n",
    "             color = cmc.cm.romaO(0.80),\n",
    "             lw = 3\n",
    "            )\n",
    "    plt.plot(x_values_von_neumann, \n",
    "             y_values_von_neumann, \n",
    "             color = cmc.cm.romaO(0.15),\n",
    "             lw = 3\n",
    "            )\n",
    "    \n",
    "    plt.hist(voroni_otsu_filtered3_df['equivalent_diameter'], \n",
    "             bins = BINS_FOR_HISTOGRAM,\n",
    "             density = True, \n",
    "             weights = ((4/3) * np.pi) * voroni_otsu_filtered3_df['equivalent_diameter']**3,\n",
    "             alpha = 0.3,\n",
    "             color = cmc.cm.romaO(0.80)\n",
    "            )\n",
    "    plt.hist(von_neumann_filtered3_df['equivalent_diameter'], \n",
    "             bins = BINS_FOR_HISTOGRAM, \n",
    "             density = True, \n",
    "             weights = ((4/3) * np.pi) * von_neumann_filtered3_df['equivalent_diameter']**3,\n",
    "             alpha = 0.3,\n",
    "             color = cmc.cm.romaO(0.15)\n",
    "            )\n",
    "    \n",
    "    plt.xlabel('vol-wt\\'d Equivalent Diameter (microns)', fontsize = ax_font_size, fontweight = 'bold')\n",
    "    plt.ylabel('Density',  fontsize = ax_font_size, fontweight = 'bold')\n",
    "    plt.xticks(fontsize=ax_font_size, fontweight='bold')\n",
    "    plt.yticks(fontsize=ax_font_size, fontweight='bold')\n",
    "    plt.box(True)\n",
    "    plt.gca().spines['top'].set_linewidth(4)    # Set top spine thickness\n",
    "    plt.gca().spines['bottom'].set_linewidth(4) # Set bottom spine thickness\n",
    "    plt.gca().spines['left'].set_linewidth(4)   # Set left spine thickness\n",
    "    plt.gca().spines['right'].set_linewidth(4)  # Set right spine thickness\n",
    "    plt.tick_params(axis='both', direction='in', length=10)  # Set the length of tick marks\n",
    "    \n",
    "    ax_vol_psd.set_ylim([0, 1])\n",
    "    ax_vol_psd.set_xlim([0, 10])\n",
    "    \n",
    "    vol_legend = plt.legend(labels = ['voroni_otsu', 'von neumann'], framealpha=1, frameon=True, fontsize=ax_font_size - 4)\n",
    "    frame = vol_legend.get_frame()\n",
    "    frame.set_edgecolor('black')  # Set legend box color\n",
    "    frame.set_linewidth(2)        # Set legend box thickness\n",
    "    for text in vol_legend.get_texts():\n",
    "        text.set_fontweight('bold')\n",
    "\n",
    "    # Add a column for volume (proportional to the cube of the diameter)\n",
    "    von_neumann_filtered3_df['Volume'] = ((4/3) * np.pi) * von_neumann_filtered3_df['equivalent_diameter'] ** 3 # CORRECT THIS TO BE THE TRUE VOLUME EQUATION\n",
    "    \n",
    "    # Calculate cumulative volume fraction\n",
    "    von_neumann_filtered3_df = von_neumann_filtered3_df.sort_values(by='equivalent_diameter').reset_index(drop=True)\n",
    "    von_neumann_filtered3_df['Volume_Cumulative'] = von_neumann_filtered3_df['Volume'].cumsum() / von_neumann_filtered3_df['Volume'].sum()\n",
    "    \n",
    "    # \"Interpolating volume-weighted d10, d50, and d90\", the numbers its spitting out are probably not interpolated like the they should be but its close enough if the dataset is large enough\n",
    "    d10_vol_von_neumann = von_neumann_filtered3_df.loc[von_neumann_filtered3_df['Volume_Cumulative'] >= 0.10, 'equivalent_diameter'].iloc[0]\n",
    "    d50_vol_von_neumann = von_neumann_filtered3_df.loc[von_neumann_filtered3_df['Volume_Cumulative'] >= 0.50, 'equivalent_diameter'].iloc[0]\n",
    "    d90_vol_von_neumann = von_neumann_filtered3_df.loc[von_neumann_filtered3_df['Volume_Cumulative'] >= 0.90, 'equivalent_diameter'].iloc[0]\n",
    "    span_vol_von_neumann = (d90_vol_von_neumann - d10_vol_von_neumann) / d50_vol_von_neumann\n",
    "    mean_vol_von_neumann = np.sum(von_neumann_filtered3_df['equivalent_diameter'] * von_neumann_filtered3_df['Volume']) / von_neumann_filtered3_df['Volume'].sum() # This is the same as the D[5,3], volume weighted size\n",
    "    std_vol_von_neumann = np.sqrt(np.sum((von_neumann_filtered3_df['equivalent_diameter'] - mean_vol_von_neumann)**2 * von_neumann_filtered3_df['Volume']) / von_neumann_filtered3_df['Volume'].sum()) #This is the calculation suggest for weighted standard deviation based on wikipedia and a stackoverflow discussion\n",
    "    \n",
    "    print(\"\\nvon Neumann, Volume-weighted distribution:\")\n",
    "    print(f\"d10, von Neumann (volume-weighted): {d10_vol_von_neumann}\")\n",
    "    print(f\"d50, von Neumann (volume-weighted): {d50_vol_von_neumann}\")\n",
    "    print(f\"d90, von Neumann (volume-weighted): {d90_vol_von_neumann}\")\n",
    "    print(f\"Span, von Neumann (volume-weighted): {span_vol_von_neumann}\")\n",
    "    print(f\"Mean, von Neumann (volume-weighted): {mean_vol_von_neumann}\")\n",
    "    print(f\"Std Deviation, von Neumann (volume-weighted): {std_vol_von_neumann}\")\n",
    "\n",
    "    \n",
    "    # Add a column for volume (proportional to the cube of the diameter)\n",
    "    voroni_otsu_filtered3_df['Volume'] = ((4/3) * np.pi) * voroni_otsu_filtered3_df['equivalent_diameter'] ** 3 # CORRECT THIS TO BE THE TRUE VOLUME EQUATION\n",
    "    \n",
    "    # Calculate cumulative volume fraction\n",
    "    voroni_otsu_filtered3_df = voroni_otsu_filtered3_df.sort_values(by='equivalent_diameter').reset_index(drop=True)\n",
    "    voroni_otsu_filtered3_df['Volume_Cumulative'] = voroni_otsu_filtered3_df['Volume'].cumsum() / voroni_otsu_filtered3_df['Volume'].sum()\n",
    "    \n",
    "    # \"Interpolating volume-weighted d10, d50, and d90\", the numbers its spitting out are probably not interpolated like the they should be but its close enough if the dataset is large enough\n",
    "    d10_vol_voroni_otsu = voroni_otsu_filtered3_df.loc[voroni_otsu_filtered3_df['Volume_Cumulative'] >= 0.10, 'equivalent_diameter'].iloc[0]\n",
    "    d50_vol_voroni_otsu = voroni_otsu_filtered3_df.loc[voroni_otsu_filtered3_df['Volume_Cumulative'] >= 0.50, 'equivalent_diameter'].iloc[0]\n",
    "    d90_vol_voroni_otsu = voroni_otsu_filtered3_df.loc[voroni_otsu_filtered3_df['Volume_Cumulative'] >= 0.90, 'equivalent_diameter'].iloc[0]\n",
    "    span_vol_voroni_otsu = (d90_vol_voroni_otsu - d10_vol_voroni_otsu) / d50_vol_voroni_otsu\n",
    "    mean_vol_voroni_otsu = np.sum(voroni_otsu_filtered3_df['equivalent_diameter'] * voroni_otsu_filtered3_df['Volume']) / voroni_otsu_filtered3_df['Volume'].sum() # This is the same as the D[5,3], volume weighted size\n",
    "    std_vol_voroni_otsu = np.sqrt(np.sum((voroni_otsu_filtered3_df['equivalent_diameter'] - mean_vol_voroni_otsu)**2 * voroni_otsu_filtered3_df['Volume']) / voroni_otsu_filtered3_df['Volume'].sum()) #This is the calculation suggest for weighted standard deviation based on wikipedia and a stackoverflow discussion\n",
    "    \n",
    "    print(\"\\nVoroni-Otsu, Volume-weighted distribution:\")\n",
    "    print(f\"d10, Voroni-Otsu (volume-weighted): {d10_vol_voroni_otsu}\")\n",
    "    print(f\"d50, Voroni-Otsu (volume-weighted): {d50_vol_voroni_otsu}\")\n",
    "    print(f\"d90, Voroni-Otsu (volume-weighted): {d90_vol_voroni_otsu}\")\n",
    "    print(f\"Span, Voroni-Otsu (volume-weighted): {span_vol_voroni_otsu}\")\n",
    "    print(f\"Mean, Voroni-Otsu (volume-weighted): {mean_vol_voroni_otsu}\")\n",
    "    print(f\"Std Deviation, Voroni-Otsu (volume-weighted): {std_vol_voroni_otsu}\")\n",
    "    \n",
    "    \n",
    "def save_domain_size_df(domain_size_df, df_type, experiment_id):\n",
    "    \"\"\" \n",
    "    Offers an option to save the statistical data as a CSV for compilation of data later \n",
    "    \"\"\" \n",
    "    domain_size_df.to_csv(f\"{experiment_id}_{df_type}.csv\")\n",
    "\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf92ce-577c-42cd-b6eb-befd678c4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't worry about it, just hit Shift+Enter and grab the image you want to analyze\n",
    "image, image_micron_scale = import_then_process_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad9e53e-a93c-4356-97b3-2c355a7afdd6",
   "metadata": {},
   "source": [
    "## Okay, now we have an image to work with for the next steps...\n",
    "\n",
    "The next step will spit out a series of thresholds, select the one which includes the active material and goes a bit over with including extra material -- we will wash out that extra material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8da720-0d2d-4d9f-874f-5a1a883d4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about it, just hit Shift+Enter \n",
    "img_binary = try_all_thresholds(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523ee8a-da90-42a8-93cd-86374ad5a068",
   "metadata": {},
   "source": [
    "## Now comes image manipulation to remove the extra\n",
    "\n",
    "We are looking to remove enough of the extra to have distinct domains that are not connected by what is clearly junk (likely binder/SE/carbon) -- this does not have to be perfect as we have ways of removing that noise later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60eff6-b050-47cf-b497-fd27e24308d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about it, just hit Shift+Enter, or change the erosion range value if you're not happy with the options\n",
    "# if erosion is not necessary then have the value equal 0\n",
    "treated_img = img_erosion_n_fill(img_binary, erosion_range = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be399a7-55b8-426c-9ade-3b6badd9f23d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##THESE FUNCTIONS SHOULD BE COMBINED TOGETHER INTO ONE\n",
    "\n",
    "binary_labels = img_binary_labeling(treated_img,\n",
    "                                    spot_sigma_val = 15,\n",
    "                                    outline_sigma_val = 0)\n",
    "\n",
    "list_dfs = img_binary_enframing(image, \n",
    "                                von_neumann_lbls = binary_labels[0], \n",
    "                                voroni_otsu_lbls = binary_labels[1],\n",
    "                                micron_per_pixel = image_micron_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09c8b87-408b-424f-83cf-888f1c599633",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Time to remove the remaining noise we picked up during labeling\n",
    "\n",
    "Below will be ECDF plots -- use your best judgement as to what is reasonable cutt off for equivalent diameter\n",
    "\n",
    "https://en.wikipedia.org/wiki/Empirical_distribution_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b67b27-3778-4864-bf13-2181a849a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about it, just hit Shift+Enter\n",
    "cutoff_particle_size(von_neumann_df = list_dfs[0], \n",
    "                     voroni_otsu_df = list_dfs[1]) #CHANGE TO HAVE A RETURN VALUE FOR THE CUTOFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb85735-6ad6-416a-9be3-5cff4d0648e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the cutoff_value to a size that you think will remove the noise while retaining the particles\n",
    "# for cathode that is probably around 0.5 to 0.7\n",
    "\n",
    "list_dfs_filtered = cutoff_particle_apply(von_neumann_df = list_dfs[0],\n",
    "                                          voroni_otsu_df = list_dfs[1],\n",
    "                                          cutoff_type = \"size\",\n",
    "                                          cutoff_value = 0.7)\n",
    "\n",
    "cutoff_particles_on_edge(von_neumann_filtered_df = list_dfs_filtered[0], \n",
    "                         voroni_otsu_filtered_df = list_dfs_filtered[1]) #CHANGE TO HAVE A RETURN VALUE FOR THE CUTOFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ba06f-10b0-407f-8cd8-2f143b0ab3b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the cutoff_value to a decimal that will remove the particles whose true size is obfuscated by being on the edge\n",
    "# my opinion is that anything with 0.15 or more should be discounted\n",
    "\n",
    "list_dfs_filtered2 = cutoff_particle_apply(von_neumann_df = list_dfs_filtered[0], \n",
    "                                           voroni_otsu_df = list_dfs_filtered[1], \n",
    "                                           cutoff_type = \"edge\", \n",
    "                                           cutoff_value = 0.15)\n",
    "\n",
    "list_dfs_filtered3 = finalize_data(von_neumann_filtered2_df = list_dfs_filtered2[0], \n",
    "                                   voroni_otsu_filtered2_df = list_dfs_filtered2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994bb4a-ffdc-491b-8736-94e2fcf0273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add notes for how to work this\n",
    "plot_and_process_particle_data(image, \n",
    "                               von_neumann_filtered3_df = list_dfs_filtered3[0], \n",
    "                               von_neumann_lbls = binary_labels[0], \n",
    "                               voroni_otsu_filtered3_df = list_dfs_filtered3[1], \n",
    "                               voroni_otsu_lbls = binary_labels[1],\n",
    "                               experiment_id_for_file = \"test\",\n",
    "                               consolidated_data = False\n",
    "                              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
